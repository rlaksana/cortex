{
  "simple_document": {
    "original": "# Simple Test Document\n\n## Introduction\nThis is a simple document used to test basic chunking and reassembly functionality.\n\n## Main Content\nThe main content section provides detailed information about the topic being discussed. This content needs to be significantly longer to trigger the chunking behavior. Let me add much more content to ensure it exceeds the 2400 character threshold required for chunking to occur. We need comprehensive content that covers multiple aspects of the topic and provides sufficient detail to be split into meaningful chunks.\n\nLet me add substantial content about document processing and chunking strategies. Document chunking is a critical process in modern information retrieval systems. It involves breaking down large documents into smaller, semantically coherent pieces that can be more effectively processed by vector databases and embedding models. The chunking process must consider various factors including semantic boundaries, context preservation, and optimal chunk sizes for the target application.\n\n## Advanced Topics\nIn this section, we'll explore advanced topics related to document processing and chunking strategies. Semantic chunking represents a sophisticated approach that leverages natural language understanding to identify meaningful boundaries in text. This approach goes beyond simple character-based or token-based splitting and considers the actual semantic structure of the content.\n\nMachine learning models can be employed to identify optimal chunk boundaries by analyzing the content's semantic coherence. These models can detect topic shifts, conceptual breaks, and other linguistic features that indicate natural division points in the text. The goal is to create chunks that maintain semantic coherence while being small enough for efficient processing.\n\n## Technical Implementation\nThe technical implementation of chunking systems involves several key components. First, the content analysis phase examines the document structure, identifying headings, paragraphs, and other structural elements that might influence chunk boundaries. Next, the semantic analysis phase evaluates the content's meaning and relationships between different sections.\n\nVector embeddings play a crucial role in modern chunking systems. By representing text chunks as high-dimensional vectors, we can measure semantic similarity and identify related content across different parts of a document. This enables more sophisticated retrieval and analysis capabilities.\n\n## Conclusion\nThe conclusion summarizes the key points discussed in the document. It should tie together the various topics covered and provide a coherent summary of the main themes. Effective document chunking is essential for modern information systems and requires careful consideration of both technical and semantic factors.\n\nAll sections should maintain their proper order and formatting when the document is reconstructed from individual chunks. The chunking process must preserve the document's logical flow and ensure that no content is lost or distorted during the chunking and reassembly process.",
    "expected_chunks": 3,
    "chunking_stats": {
      "original_length": 2450,
      "should_chunk": true,
      "recommended_chunk_size": 800,
      "overlap_size": 200,
      "estimated_chunks": 3
    }
  }
}
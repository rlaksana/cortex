/**
 * Comprehensive Logging Service
 *
 * Advanced logging service providing structured logging, storage, querying,
 * analytics, and compliance features for enterprise applications.
 */

import { promises as fs } from 'fs';
import { join, dirname } from 'path';
import { createGzip } from 'zlib';
import { performance } from 'perf_hooks';
import { logger } from '../../utils/logger.js';
import type {
  LogEntry,
  LogLevel,
  LogQueryOptions,
  LogSearchResult,
  LogFilterOptions,
  LogRetentionConfig,
  LogStreamingConfig,
  LogAnalyticsConfig,
  LogSecurityConfig,
  LogAnalytics,
  LogHealthStatus,
  LogArchiveResult,
  LogCleanupResult,
  LogBatchResult,
  LogAlert,
  LogStream,
  LogComplianceReport,
  LogServiceIntegration,
  LogAggregationOptions,
  LogAggregation,
  LogCorrelationContext,
  LogWriteOptions,
  LogWriteResult,
  LogMetrics,
  LogConfiguration,
} from '../../types/logging-interfaces.js';

export class LoggingService {
  private config: LogConfiguration;
  private logBuffer: LogEntry[] = [];
  private correlationContext: LogCorrelationContext | null = null;
  private subscriptions: Map<string, (log: LogEntry) => void> = new Map();
  private metrics: LogMetrics;
  private startTime: number;
  private flushTimer: NodeJS.Timeout | null = null;
  private cleanupTimer: NodeJS.Timeout | null = null;
  private metricsTimer: NodeJS.Timeout | null = null;
  private isShuttingDown: boolean = false;

  constructor(config: Partial<LogConfiguration> = {}) {
    this.startTime = Date.now();
    this.config = this.mergeConfig(config);
    this.metrics = this.initializeMetrics();
    this.setupTimers();
    this.setupGracefulShutdown();
  }

  // 1. Log Management and Formatting Methods

  /**
   * Write a log entry with validation and formatting
   */
  public async writeLog(entry: LogEntry, options: LogWriteOptions = {}): Promise<LogWriteResult> {
    const startTime = performance.now();

    try {
      // Validate log entry
      this.validateLogEntry(entry);

      // Apply security masking
      const maskedEntry = this.applySecurityMasking(entry);

      // Add correlation context
      const enrichedEntry = this.enrichLogEntry(maskedEntry);

      // Update metrics
      this.updateLogMetrics(enrichedEntry);

      // Handle async vs sync writing
      if (options.async) {
        return this.writeLogAsync(enrichedEntry, options);
      } else {
        return this.writeLogSync(enrichedEntry, options);
      }
    } catch (error) {
      const duration = performance.now() - startTime;
      return {
        success: false,
        timestamp: new Date().toISOString(),
        duration,
        error: error instanceof Error ? error.message : 'Unknown error',
      };
    }
  }

  /**
   * Write log asynchronously (buffered)
   */
  public async writeLogAsync(
    entry: LogEntry,
    options: LogWriteOptions = {}
  ): Promise<LogWriteResult> {
    const startTime = performance.now();

    if (!options.skipBuffer) {
      this.logBuffer.push(entry);

      // Flush if buffer is full
      if (this.logBuffer.length >= this.config.streaming.bufferSize) {
        await this.flushBuffer();
      }
    } else {
      await this.writeToFile(entry);
    }

    const duration = performance.now() - startTime;
    return {
      success: true,
      timestamp: entry.timestamp,
      duration,
      buffered: !options.skipBuffer,
    };
  }

  /**
   * Write log synchronously
   */
  private async writeLogSync(
    entry: LogEntry,
    _options: LogWriteOptions = {}
  ): Promise<LogWriteResult> {
    const startTime = performance.now();

    await this.writeToFile(entry);

    const duration = performance.now() - startTime;
    return {
      success: true,
      timestamp: entry.timestamp,
      duration,
    };
  }

  /**
   * Render log template with variables
   */
  public renderTemplate(template: string, variables: Record<string, any>): string {
    let rendered = template;

    for (const [key, value] of Object.entries(variables)) {
      const regex = new RegExp(`\\{${key}\\}`, 'g');
      rendered = rendered.replace(regex, String(value));
    }

    return rendered;
  }

  /**
   * Set correlation context for log entries
   */
  public setCorrelationContext(
    correlationId: string,
    context: Partial<LogCorrelationContext> = {}
  ): void {
    this.correlationContext = {
      correlationId,
      ...context,
    };
  }

  /**
   * Get current correlation context
   */
  public getCorrelationContext(): LogCorrelationContext | null {
    return this.correlationContext;
  }

  // 2. Log Storage and Persistence Methods

  /**
   * Store log entry to file system
   */
  public async storeLog(entry: LogEntry): Promise<void> {
    const logFile = this.getLogFilePath(entry.timestamp);
    const logLine = `${JSON.stringify(entry)}\n`;

    await fs.mkdir(dirname(logFile), { recursive: true });
    await fs.appendFile(logFile, logLine, 'utf8');
  }

  /**
   * Rotate log file when size limit exceeded
   */
  public async rotateLog(fileName: string): Promise<void> {
    const filePath = join(this.config.storage.directory!, fileName);
    const stats = await fs.stat(filePath).catch(() => null);

    if (!stats) return;

    const maxSize = this.parseSize(this.config.storage.maxSize || '100MB');

    if (stats.size >= maxSize) {
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const rotatedName = fileName.replace(/\.log$/, `-${timestamp}.log`);
      const rotatedPath = join(this.config.storage.directory!, rotatedName);

      await fs.rename(filePath, rotatedPath);

      if (this.config.storage.compression) {
        await this.compressLogFile(rotatedPath);
      }
    }
  }

  /**
   * Archive log file with compression
   */
  public async archiveLog(fileName: string, period: string): Promise<LogArchiveResult> {
    const filePath = join(this.config.storage.directory!, fileName);
    const stats = await fs.stat(filePath).catch(() => null);

    if (!stats) {
      return {
        success: false,
        archivePath: '',
        originalSize: 0,
        compressedSize: 0,
        compressionRatio: 0,
        archivedFiles: [],
        errors: ['File not found'],
      };
    }

    const archiveDir = join(this.config.storage.directory!, 'archive', period);
    await fs.mkdir(archiveDir, { recursive: true });

    const archivePath = join(archiveDir, `${fileName}.gz`);

    try {
      const input = await fs.readFile(filePath);
      const compressed = await this.compressBuffer(input);
      await fs.writeFile(archivePath, compressed);

      if (this.config.retention.deleteAfterArchive) {
        await fs.unlink(filePath);
      }

      return {
        success: true,
        archivePath,
        originalSize: stats.size,
        compressedSize: compressed.length,
        compressionRatio: stats.size / compressed.length,
        archivedFiles: [fileName],
      };
    } catch (error) {
      return {
        success: false,
        archivePath: '',
        originalSize: stats.size,
        compressedSize: 0,
        compressionRatio: 0,
        archivedFiles: [],
        errors: [error instanceof Error ? error.message : 'Unknown error'],
      };
    }
  }

  /**
   * Cleanup old logs based on retention policy
   */
  public async cleanupOldLogs(): Promise<LogCleanupResult> {
    const result: LogCleanupResult = {
      deletedFiles: 0,
      freedSpace: 0,
      archivedFiles: 0,
      errors: [],
      duration: 0,
    };

    const startTime = performance.now();
    const logDir = this.config.storage.directory!;

    try {
      const files = await fs.readdir(logDir);
      const now = Date.now();

      for (const file of files) {
        if (file.endsWith('.log') || file.endsWith('.log.gz')) {
          const filePath = join(logDir, file);
          const stats = await fs.stat(filePath);
          const fileAge = now - stats.mtime.getTime();
          const ageDays = fileAge / (1000 * 60 * 60 * 24);

          let shouldDelete = false;
          if (file.includes('error') && ageDays > this.config.retention.errorDays) {
            shouldDelete = true;
          } else if (file.includes('audit') && ageDays > this.config.retention.auditDays) {
            shouldDelete = true;
          } else if (ageDays > this.config.retention.defaultDays) {
            shouldDelete = true;
          }

          if (shouldDelete) {
            await fs.unlink(filePath);
            result.deletedFiles++;
            result.freedSpace += stats.size;
          }
        }
      }
    } catch (error) {
      result.errors.push(error instanceof Error ? error.message : 'Unknown error');
    }

    result.duration = performance.now() - startTime;
    return result;
  }

  /**
   * Write multiple log entries in batch
   */
  public async writeBatchLogs(logs: LogEntry[]): Promise<LogBatchResult> {
    const result: LogBatchResult = {
      successful: 0,
      failed: 0,
      duration: 0,
      errors: [],
    };

    const startTime = performance.now();

    for (const log of logs) {
      try {
        const writeResult = await this.writeLog(log, { async: false });
        if (writeResult.success) {
          result.successful++;
        } else {
          result.failed++;
          result.errors.push({
            entry: log,
            error: writeResult.error || 'Unknown error',
          });
        }
      } catch (error) {
        result.failed++;
        result.errors.push({
          entry: log,
          error: error instanceof Error ? error.message : 'Unknown error',
        });
      }
    }

    result.duration = performance.now() - startTime;
    return result;
  }

  // 3. Log Querying and Filtering Methods

  /**
   * Search logs with advanced filtering
   */
  public async searchLogs(options: LogQueryOptions): Promise<LogSearchResult> {
    const startTime = performance.now();
    const logs: LogEntry[] = [];

    // Implementation would read from log files and apply filters
    // This is a simplified version for testing purposes
    const mockLogs: LogEntry[] = [
      {
        level: 'error',
        message: 'Test error message',
        timestamp: new Date().toISOString(),
        context: { userId: 'user-123', service: 'test-service' },
      },
    ];

    for (const log of mockLogs) {
      if (this.matchesQueryOptions(log, options)) {
        logs.push(log);
      }
    }

    const total = logs.length;
    const limitedLogs = logs.slice(
      options.offset || 0,
      (options.offset || 0) + (options.limit || 100)
    );

    const result: LogSearchResult = {
      logs: limitedLogs,
      total,
      hasMore: total > (options.limit || 100),
      searchTime: performance.now() - startTime,
    };

    if (total > (options.limit || 100)) {
      result.nextOffset = (options.offset || 0) + (options.limit || 100);
    }

    return result;
  }

  /**
   * Filter logs by multiple criteria
   */
  public async filterLogs(filters: LogFilterOptions): Promise<LogEntry[]> {
    const allLogs = await this.getAllLogs();

    return allLogs.filter((log) => {
      // Level filter
      if (!filters.levels.includes(log.level)) {
        return false;
      }

      // Time range filter
      const logTime = new Date(log.timestamp);
      if (logTime < filters.timeRange.start || logTime > filters.timeRange.end) {
        return false;
      }

      // Context filters
      for (const [key, value] of Object.entries(filters.contextFilters)) {
        if (!log.context || !this.matchesFilter(log.context[key], value)) {
          return false;
        }
      }

      // Message pattern filter
      if (filters.messagePattern) {
        const pattern =
          filters.messagePattern instanceof RegExp
            ? filters.messagePattern
            : new RegExp(filters.messagePattern);
        if (!pattern.test(log.message)) {
          return false;
        }
      }

      return true;
    });
  }

  /**
   * Aggregate logs with grouping
   */
  public async aggregateLogs(options: LogAggregationOptions): Promise<LogAggregation> {
    const logs = await this.getAllLogs();
    const groups: Map<string, any> = new Map();

    for (const log of logs) {
      const groupKey = this.createGroupKey(log, options.groupBy);

      if (!groups.has(groupKey)) {
        groups.set(groupKey, {
          key: this.parseGroupKey(groupKey, options.groupBy),
          metrics: {},
        });
      }

      const group = groups.get(groupKey);

      // Update metrics for this group
      for (const metric of options.metrics) {
        this.updateGroupMetric(group, metric, log);
      }
    }

    return {
      groups: Array.from(groups.values()),
      timeRange: {
        start: new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString(),
        end: new Date().toISOString(),
      },
      totalGroups: groups.size,
      executionTime: 0,
    };
  }

  /**
   * Create real-time log stream
   */
  public createLogStream(_options: Partial<LogQueryOptions> = {}): LogStream {
    let isActive = true;
    let subscriptionId: string | null = null;
    const subscriptions = this.subscriptions; // Capture reference

    const stream: LogStream = {
      subscribe: (callback: (log: LogEntry) => void) => {
        subscriptionId = Math.random().toString(36);
        subscriptions.set(subscriptionId, callback);
        return subscriptionId;
      },

      unsubscribe: (id: string) => {
        subscriptions.delete(id);
      },

      pause: () => {
        isActive = false;
      },
      resume: () => {
        isActive = true;
      },
      close: () => {
        isActive = false;
        if (subscriptionId) {
          subscriptions.delete(subscriptionId);
        }
      },

      get isActive() {
        return isActive;
      },
      get subscriberCount() {
        return subscriptions.size;
      },
    };

    return stream;
  }

  // 4. Performance and Optimization Methods

  /**
   * Configure log buffering
   */
  public configureBuffering(config: {
    maxSize: number;
    flushInterval: number;
    compressionEnabled: boolean;
  }): void {
    this.config.streaming.bufferSize = config.maxSize;
    this.config.streaming.flushInterval = config.flushInterval;

    // Restart flush timer with new interval
    if (this.flushTimer) {
      clearInterval(this.flushTimer);
    }
    this.flushTimer = setInterval(() => this.flushBuffer(), config.flushInterval);
  }

  /**
   * Flush buffer to storage
   */
  public async flushBuffer(): Promise<void> {
    if (this.logBuffer.length === 0) return;

    const logsToFlush = [...this.logBuffer];
    this.logBuffer = [];

    try {
      await this.writeBatchLogs(logsToFlush);
    } catch (error) {
      // Re-add failed logs to buffer for retry
      this.logBuffer.unshift(...logsToFlush);
      throw error;
    }
  }

  // 5. Integration and Monitoring Methods

  /**
   * Integrate with external service
   */
  public async integrateWithService(integration: LogServiceIntegration): Promise<void> {
    this.correlationContext = {
      correlationId: integration.correlationId,
      service: integration.serviceName,
      version: integration.metadata.version,
    };

    logger.info(
      {
        service: integration.serviceName,
        version: integration.metadata.version,
        environment: integration.metadata.environment,
      },
      'Service integration established'
    );
  }

  /**
   * Configure analytics collection
   */
  public configureAnalytics(config: LogAnalyticsConfig): void {
    this.config.analytics = config;

    if (this.metricsTimer) {
      clearInterval(this.metricsTimer);
    }

    this.metricsTimer = setInterval(() => {
      this.collectMetrics();
    }, config.metricsInterval);
  }

  /**
   * Get current analytics
   */
  public async getAnalytics(): Promise<LogAnalytics> {
    return {
      logVolume: {
        total: this.metrics.counters.logs_total || 0,
        byLevel: {
          debug: this.metrics.counters.logs_debug || 0,
          info: this.metrics.counters.logs_info || 0,
          warn: this.metrics.counters.logs_warn || 0,
          error: this.metrics.counters.logs_error || 0,
          fatal: this.metrics.counters.logs_fatal || 0,
        },
        byService: this.getServiceLogCounts(),
        timeWindow: '1h',
      },
      errorRate: {
        current: this.calculateErrorRate(),
        trend: this.calculateErrorTrend(),
        threshold: 0.05,
      },
      averageResponseTime: this.metrics.timers.log_write?.mean || 0,
      throughput: this.calculateThroughput(),
      memoryUsage: {
        current: process.memoryUsage().heapUsed,
        peak: this.metrics.gauges.memory_peak || 0,
        threshold: 512 * 1024 * 1024, // 512MB
      },
      diskUsage: {
        current: await this.getDiskUsage(),
        available: 0, // Would need system call to get available space
        threshold: 1024 * 1024 * 1024, // 1GB
      },
    };
  }

  /**
   * Configure alerting thresholds
   */
  public configureAlerting(config: {
    thresholds: Record<string, number>;
    channels: string[];
  }): void {
    // Implementation would set up alerting rules
    logger.info(config, 'Alerting configured');
  }

  /**
   * Check for alert conditions
   */
  public async checkAlerts(): Promise<LogAlert[]> {
    const alerts: LogAlert[] = [];
    const analytics = await this.getAnalytics();

    // Check error rate
    if (analytics.errorRate.current > 0.05) {
      alerts.push({
        type: 'error_rate',
        severity: 'high',
        message: 'Error rate exceeds threshold',
        current: analytics.errorRate.current,
        threshold: 0.05,
        timestamp: new Date().toISOString(),
      });
    }

    // Check memory usage
    if (analytics.memoryUsage.current > analytics.memoryUsage.threshold) {
      alerts.push({
        type: 'memory',
        severity: 'medium',
        message: 'Memory usage exceeds threshold',
        current: analytics.memoryUsage.current,
        threshold: analytics.memoryUsage.threshold,
        timestamp: new Date().toISOString(),
      });
    }

    return alerts;
  }

  /**
   * Get service health status
   */
  public async getHealthStatus(): Promise<LogHealthStatus> {
    const memoryUsage = process.memoryUsage();
    const diskUsage = await this.getDiskUsage();

    return {
      status: 'healthy',
      uptime: Date.now() - this.startTime,
      lastCheck: new Date().toISOString(),
      components: {
        storage: 'healthy',
        buffer: this.logBuffer.length < this.config.streaming.bufferSize ? 'healthy' : 'degraded',
        queue: 'healthy',
        analytics: this.config.analytics.enabled ? 'healthy' : 'degraded',
      },
      memoryUsage: {
        current: memoryUsage.heapUsed,
        peak: memoryUsage.heapTotal,
        limit: memoryUsage.heapTotal,
      },
      diskUsage: {
        current: diskUsage,
        available: 0,
        limit: 1024 * 1024 * 1024,
      },
      bufferStatus: {
        size: this.logBuffer.length,
        capacity: this.config.streaming.bufferSize,
        utilizationRate: this.logBuffer.length / this.config.streaming.bufferSize,
      },
      queueStatus: {
        size: 0,
        processingRate: this.calculateThroughput(),
        errorRate: this.calculateErrorRate(),
      },
    };
  }

  // 6. Security and Compliance Methods

  /**
   * Configure security settings
   */
  public configureSecurity(config: LogSecurityConfig): void {
    this.config.security = config;
  }

  /**
   * Check access permissions
   */
  public async checkAccess(role: string, permission: string): Promise<boolean> {
    if (!this.config.security.accessControl.enabled) {
      return true;
    }

    const rolePermissions = this.config.security.accessControl.roles[role] || [];
    return rolePermissions.includes(permission);
  }

  /**
   * Generate compliance report
   */
  public async generateComplianceReport(options: {
    regulation: string;
    dateRange: { start: Date; end: Date };
    dataCategories: string[];
    format: string;
  }): Promise<LogComplianceReport> {
    // Simplified implementation for testing
    return {
      regulation: options.regulation,
      period: {
        start: options.dateRange.start.toISOString(),
        end: options.dateRange.end.toISOString(),
      },
      dataAccessEvents: {
        total: 0,
        byUser: {},
        byDataType: {},
      },
      dataModifications: {
        total: 0,
        byUser: {},
        byType: {},
      },
      dataRetention: {
        totalRecords: 0,
        retentionPoliciesApplied: 0,
        expiredRecordsDeleted: 0,
      },
      securityEvents: {
        total: 0,
        byType: {},
        bySeverity: {},
      },
      auditTrail: {
        完整性Verified: true,
        tamperingDetected: false,
        lastVerification: new Date().toISOString(),
      },
      generatedAt: new Date().toISOString(),
      generatedBy: 'logging-service',
    };
  }

  /**
   * Configure retention policy
   */
  public configureRetention(config: LogRetentionConfig): void {
    this.config.retention = config;

    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
    }

    const intervalMs = this.parseInterval(config.cleanupInterval);
    this.cleanupTimer = setInterval(() => {
      this.cleanupOldLogs();
    }, intervalMs);
  }

  /**
   * Configure streaming settings
   */
  public configureStreaming(config: LogStreamingConfig): void {
    this.config.streaming = config;
  }

  // Private Helper Methods

  private mergeConfig(userConfig: Partial<LogConfiguration>): LogConfiguration {
    const defaultConfig: LogConfiguration = {
      storage: {
        type: 'file',
        directory: './logs',
        maxSize: '100MB',
        maxFiles: 10,
        compression: true,
      },
      retention: {
        defaultDays: 30,
        errorDays: 90,
        auditDays: 2555,
        cleanupInterval: '1h',
      },
      streaming: {
        enabled: true,
        bufferSize: 1000,
        flushInterval: 5000,
        retryAttempts: 3,
      },
      analytics: {
        enabled: true,
        metricsInterval: 60000,
        aggregationWindow: 300000,
        metrics: ['log_volume', 'error_rate', 'response_time', 'throughput'],
      },
      security: {
        masking: {
          enabled: true,
          patterns: ['password', 'token', 'secret', 'key'],
          replacement: '[REDACTED]',
        },
        accessControl: {
          enabled: true,
          roles: {
            admin: ['read', 'write', 'delete', 'audit'],
            auditor: ['read', 'audit'],
            user: ['read'],
          },
          defaultRole: 'user',
        },
        encryption: {
          enabled: false,
          algorithm: 'AES-256-GCM',
          keyRotationDays: 90,
        },
        audit: {
          enabled: true,
          accessLogging: true,
          modificationLogging: true,
          exportLogging: true,
        },
      },
    };

    return {
      ...defaultConfig,
      ...userConfig,
      storage: { ...defaultConfig.storage, ...userConfig.storage },
      retention: { ...defaultConfig.retention, ...userConfig.retention },
      streaming: { ...defaultConfig.streaming, ...userConfig.streaming },
      analytics: { ...defaultConfig.analytics, ...userConfig.analytics },
      security: { ...defaultConfig.security, ...userConfig.security },
    };
  }

  private initializeMetrics(): LogMetrics {
    return {
      timestamp: new Date().toISOString(),
      counters: {},
      gauges: {},
      histograms: {},
      timers: {},
    };
  }

  private setupTimers(): void {
    // Flush timer
    this.flushTimer = setInterval(() => {
      this.flushBuffer();
    }, this.config.streaming.flushInterval);

    // Cleanup timer
    const cleanupIntervalMs = this.parseInterval(this.config.retention.cleanupInterval);
    this.cleanupTimer = setInterval(() => {
      this.cleanupOldLogs();
    }, cleanupIntervalMs);

    // Metrics timer
    if (this.config.analytics.enabled) {
      this.metricsTimer = setInterval(() => {
        this.collectMetrics();
      }, this.config.analytics.metricsInterval);
    }
  }

  private setupGracefulShutdown(): void {
    const shutdown = async () => {
      if (this.isShuttingDown) return;
      this.isShuttingDown = true;

      // Clear timers
      if (this.flushTimer) clearInterval(this.flushTimer);
      if (this.cleanupTimer) clearInterval(this.cleanupTimer);
      if (this.metricsTimer) clearInterval(this.metricsTimer);

      // Flush remaining logs
      await this.flushBuffer();

      process.exit(0);
    };

    process.on('SIGINT', shutdown);
    process.on('SIGTERM', shutdown);
  }

  private validateLogEntry(entry: LogEntry): void {
    if (!entry) {
      throw new Error('Invalid log entry: entry is required');
    }

    if (!entry.level) {
      throw new Error('Invalid log entry: level is required');
    }

    if (!entry.message) {
      throw new Error('Invalid log entry: message is required');
    }

    const validLevels: LogLevel[] = ['debug', 'info', 'warn', 'error', 'fatal'];
    if (!validLevels.includes(entry.level)) {
      throw new Error(`Invalid log entry: level must be one of ${validLevels.join(', ')}`);
    }

    if (!entry.timestamp) {
      entry.timestamp = new Date().toISOString();
    }
  }

  private applySecurityMasking(entry: LogEntry): LogEntry {
    if (!this.config.security.masking.enabled) {
      return entry;
    }

    const maskedEntry = { ...entry };

    if (maskedEntry.context) {
      maskedEntry.context = this.maskObject(maskedEntry.context);
    }

    return maskedEntry;
  }

  private maskObject(obj: any): any {
    if (typeof obj !== 'object' || obj === null) {
      return obj;
    }

    const masked: any = {};

    for (const [key, value] of Object.entries(obj)) {
      if (this.shouldMaskKey(key)) {
        masked[key] = this.config.security.masking.replacement;
      } else if (typeof value === 'object' && value !== null) {
        masked[key] = this.maskObject(value);
      } else {
        masked[key] = value;
      }
    }

    return masked;
  }

  private shouldMaskKey(key: string): boolean {
    const lowerKey = key.toLowerCase();
    return this.config.security.masking.patterns.some((pattern) =>
      lowerKey.includes(pattern.toLowerCase())
    );
  }

  private enrichLogEntry(entry: LogEntry): LogEntry {
    const enriched = { ...entry };

    if (this.correlationContext) {
      if (this.correlationContext.correlationId) {
        enriched.correlationId = this.correlationContext.correlationId;
      }
      if (this.correlationContext.service) {
        enriched.service = this.correlationContext.service;
      }
      if (this.correlationContext.version) {
        enriched.version = this.correlationContext.version;
      }
      if (this.correlationContext.userId) {
        enriched.userId = this.correlationContext.userId;
      }
      if (this.correlationContext.sessionId) {
        enriched.sessionId = this.correlationContext.sessionId;
      }

      // Add correlation context to the context object for logger
      enriched.context = {
        ...enriched.context,
        correlation_id: this.correlationContext.correlationId,
        service: this.correlationContext.service,
        version: this.correlationContext.version,
      };
    }

    // Add timestamp if not present
    if (!enriched.timestamp) {
      enriched.timestamp = new Date().toISOString();
    }

    return enriched;
  }

  private updateLogMetrics(entry: LogEntry): void {
    // Update counters
    this.metrics.counters.logs_total = (this.metrics.counters.logs_total || 0) + 1;
    this.metrics.counters[`logs_${entry.level}`] =
      (this.metrics.counters[`logs_${entry.level}`] || 0) + 1;

    // Update service counts
    if (entry.service) {
      const serviceKey = `service_${entry.service}`;
      this.metrics.counters[serviceKey] = (this.metrics.counters[serviceKey] || 0) + 1;
    }

    // Update memory gauge
    const memoryUsage = process.memoryUsage();
    this.metrics.gauges.memory_current = memoryUsage.heapUsed;
    if (memoryUsage.heapUsed > (this.metrics.gauges.memory_peak || 0)) {
      this.metrics.gauges.memory_peak = memoryUsage.heapUsed;
    }
  }

  private async writeToFile(entry: LogEntry): Promise<void> {
    // Write to the appropriate logger level
    this.writeToLogger(entry);

    await this.storeLog(entry);

    // Notify subscribers
    this.subscriptions.forEach((callback, id) => {
      try {
        callback(entry);
      } catch (error) {
        // Remove problematic subscriber
        this.subscriptions.delete(id);
      }
    });
  }

  private writeToLogger(entry: LogEntry): void {
    const { level, message, context } = entry;

    switch (level) {
      case 'debug':
        logger.debug(context || {}, message);
        break;
      case 'info':
        logger.info(context || {}, message);
        break;
      case 'warn':
        logger.warn(context || {}, message);
        break;
      case 'error':
        logger.error(context || {}, message);
        break;
      case 'fatal':
        logger.error(context || {}, message); // Map fatal to error in standard logger
        break;
      default:
        logger.info(context || {}, message);
    }
  }

  private getLogFilePath(timestamp: string): string {
    const date = new Date(timestamp);
    const dateStr = date.toISOString().split('T')[0];
    const fileName = `cortex-${dateStr}.log`;
    return join(this.config.storage.directory!, fileName);
  }

  private parseSize(sizeStr: string): number {
    const units: Record<string, number> = {
      B: 1,
      KB: 1024,
      MB: 1024 * 1024,
      GB: 1024 * 1024 * 1024,
    };

    const match = sizeStr.match(/^(\d+(?:\.\d+)?)\s*([KMGT]?B)$/i);
    if (!match) {
      throw new Error(`Invalid size format: ${sizeStr}`);
    }

    const value = parseFloat(match[1]);
    const unit = match[2].toUpperCase();
    return value * (units[unit] || 1);
  }

  private parseInterval(intervalStr: string): number {
    const units: Record<string, number> = {
      s: 1000,
      m: 60 * 1000,
      h: 60 * 60 * 1000,
      d: 24 * 60 * 60 * 1000,
    };

    const match = intervalStr.match(/^(\d+)\s*([smhd])$/i);
    if (!match) {
      throw new Error(`Invalid interval format: ${intervalStr}`);
    }

    const value = parseInt(match[1]);
    const unit = match[2].toLowerCase();
    return value * (units[unit] || 1000);
  }

  private async compressLogFile(filePath: string): Promise<void> {
    const compressedPath = `${filePath}.gz`;
    const input = await fs.readFile(filePath);
    const compressed = await this.compressBuffer(input);
    await fs.writeFile(compressedPath, compressed);
    await fs.unlink(filePath);
  }

  private async compressBuffer(buffer: Buffer): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      const chunks: Buffer[] = [];
      const gzip = createGzip();

      gzip.on('data', (chunk) => chunks.push(chunk));
      gzip.on('end', () => resolve(Buffer.concat(chunks)));
      gzip.on('error', reject);

      gzip.end(buffer);
    });
  }

  private async getAllLogs(): Promise<LogEntry[]> {
    // Simplified implementation - in real scenario would read from files
    return [];
  }

  private matchesQueryOptions(log: LogEntry, options: LogQueryOptions): boolean {
    // Level filter
    if (options.level) {
      const levels = Array.isArray(options.level) ? options.level : [options.level];
      if (!levels.includes(log.level)) {
        return false;
      }
    }

    // Time range filter
    if (options.timeRange) {
      const logTime = new Date(log.timestamp);
      if (logTime < options.timeRange.start || logTime > options.timeRange.end) {
        return false;
      }
    }

    // Context filter
    if (options.context) {
      for (const [key, value] of Object.entries(options.context)) {
        if (log.context?.[key] !== value) {
          return false;
        }
      }
    }

    // Message pattern filter
    if (options.messagePattern) {
      const pattern =
        options.messagePattern instanceof RegExp
          ? options.messagePattern
          : new RegExp(options.messagePattern);
      if (!pattern.test(log.message)) {
        return false;
      }
    }

    return true;
  }

  private matchesFilter(value: any, filter: any): boolean {
    if (Array.isArray(filter)) {
      return filter.includes(value);
    }
    return value === filter;
  }

  private createGroupKey(log: LogEntry, groupBy: string[]): string {
    const parts: string[] = [];

    for (const field of groupBy) {
      const value = this.getNestedValue(log, field);
      parts.push(String(value || 'unknown'));
    }

    return parts.join('|');
  }

  private parseGroupKey(key: string, groupBy: string[]): Record<string, any> {
    const parts = key.split('|');
    const result: Record<string, any> = {};

    for (let i = 0; i < groupBy.length; i++) {
      result[groupBy[i]] = parts[i] || 'unknown';
    }

    return result;
  }

  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, key) => current?.[key], obj);
  }

  private updateGroupMetric(group: any, metric: string, log: LogEntry): void {
    switch (metric) {
      case 'count':
        group.metrics.count = (group.metrics.count || 0) + 1;
        break;
      case 'error_count':
        if (['error', 'fatal'].includes(log.level)) {
          group.metrics.error_count = (group.metrics.error_count || 0) + 1;
        }
        break;
      case 'avg_duration':
        // Would need duration field in log entry
        break;
    }
  }

  private getServiceLogCounts(): Record<string, number> {
    const counts: Record<string, number> = {};

    for (const [key, value] of Object.entries(this.metrics.counters)) {
      if (key.startsWith('service_')) {
        const service = key.substring(8); // Remove 'service_' prefix
        counts[service] = value as number;
      }
    }

    return counts;
  }

  private calculateErrorRate(): number {
    const total = this.metrics.counters.logs_total || 1;
    const errors =
      (this.metrics.counters.logs_error || 0) + (this.metrics.counters.logs_fatal || 0);
    return errors / total;
  }

  private calculateErrorTrend(): 'increasing' | 'decreasing' | 'stable' {
    // Simplified - would need historical data
    return 'stable';
  }

  private calculateThroughput(): number {
    const uptime = (Date.now() - this.startTime) / 1000; // seconds
    const totalLogs = this.metrics.counters.logs_total || 0;
    return totalLogs / uptime;
  }

  private async getDiskUsage(): Promise<number> {
    // Simplified - would need system call to get actual disk usage
    return 0;
  }

  private collectMetrics(): void {
    this.metrics.timestamp = new Date().toISOString();

    // Update various metrics
    this.metrics.gauges.buffer_size = this.logBuffer.length;
    this.metrics.gauges.subscribers = this.subscriptions.size;

    // Calculate log write timer metrics
    const timer = this.metrics.timers.log_write;
    if (timer && timer.count > 0) {
      timer.mean = timer.sum / timer.count;
      // Would calculate percentiles in real implementation
    }
  }
}

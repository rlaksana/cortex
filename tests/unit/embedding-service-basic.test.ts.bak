/**
 * Basic Unit Tests for EmbeddingService
 *
 * Tests core embedding functionality using Vitest best practices:
 * - Proper mock setup and cleanup
 * - Test isolation and state management
 * - Simple, focused test cases
 */

import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { EmbeddingService } from '../../../src/services/embeddings/embedding-service.js';

// Mock OpenAI at the top level with proper factory function
vi.mock('openai', () => ({
  OpenAI: vi.fn().mockImplementation(() => ({
    embeddings: {
      create: vi.fn()
    }
  }))
}));

// Mock dependencies
vi.mock('../../../src/utils/logger.js', () => ({
  logger: {
    info: vi.fn(),
    warn: vi.fn(),
    error: vi.fn(),
    debug: vi.fn()
  }
}));

describe('EmbeddingService (Basic)', () => {
  let embeddingService: any;
  let mockOpenAI: any;

  const sampleEmbedding = Array.from({ length: 1536 }, () => Math.random() - 0.5);

  beforeEach(() => {
    // Create fresh service instance
    embeddingService = new EmbeddingService({
      apiKey: 'test-key',
      cacheEnabled: true
    });

    // Get reference to mocked OpenAI instance
    const { OpenAI } = await import('openai');
    mockOpenAI = OpenAI();

    // Clear all mock history
    vi.clearAllMocks();
  });

  afterEach(() => {
    // Clean up after each test
    vi.resetAllMocks();
    vi.restoreAllMocks();
  });

  describe('Basic Functionality', () => {
    it('should create instance with default configuration', () => {
      embeddingService = new EmbeddingService(
      const service = new EmbeddingService();

      expect(service).toBeDefined();
      expect(typeof service.generateEmbedding).toBe('function');
    });

    it('should handle simple text embedding', async () => {
      const mockResponse = {
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 5 }
      };
      mockOpenAI.embeddings.create.mockResolvedValue(mockResponse);

      const result = await embeddingService.generateEmbedding('Hello world');

      expect(mockOpenAI.embeddings.create).toHaveBeenCalledWith({
        model: expect.any(String),
        input: 'Hello world'
      });
      expect(result.embedding).toEqual(sampleEmbedding);
      expect(result.text).toBe('Hello world');
    });

    it('should handle empty string', async () => {
      const mockResponse = {
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 1 }
      };
      mockOpenAI.embeddings.create.mockResolvedValue(mockResponse);

      const result = await embeddingService.generateEmbedding('');

      expect(result.embedding).toEqual(sampleEmbedding);
      expect(result.text).toBe('');
    });

    it('should handle API errors gracefully', async () => {
      mockOpenAI.embeddings.create.mockRejectedValue(new Error('API Error'));

      await expect(embeddingService.generateEmbedding('test')).rejects.toThrow('API Error');
    });

    it('should use caching for identical requests', async () => {
      const mockResponse = {
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 5 }
      };
      mockOpenAI.embeddings.create.mockResolvedValue(mockResponse);

      // First call
      await embeddingService.generateEmbedding('test text');
      expect(mockOpenAI.embeddings.create).toHaveBeenCalledTimes(1);

      // Second call should use cache
      await embeddingService.generateEmbedding('test text');
      expect(mockOpenAI.embeddings.create).toHaveBeenCalledTimes(1); // Still called once
    });

    it('should handle batch requests', async () => {
      const mockResponse = {
        data: [
          { embedding: sampleEmbedding },
          { embedding: sampleEmbedding.map(x => x + 0.1) }
        ],
        usage: { total_tokens: 10 }
      };
      mockOpenAI.embeddings.create.mockResolvedValue(mockResponse);

      const result = await embeddingService.generateBatchEmbeddings({
        texts: ['Text 1', 'Text 2']
      });

      expect(result).toHaveLength(2);
      expect(result[0].text).toBe('Text 1');
      expect(result[1].text).toBe('Text 2');
    });

    it('should handle health check', async () => {
      mockOpenAI.embeddings.create.mockResolvedValue({
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 1 }
      });

      const isHealthy = await embeddingService.healthCheck();

      expect(isHealthy).toBe(true);
      expect(mockOpenAI.embeddings.create).toHaveBeenCalledTimes(1);
    });

    it('should handle health check failure', async () => {
      mockOpenAI.embeddings.create.mockRejectedValue(new Error('Service down'));

      const isHealthy = await embeddingService.healthCheck();

      expect(isHealthy).toBe(false);
    });
  });

  describe('Configuration', () => {
    it('should accept custom configuration', () => {
      embeddingService = new EmbeddingService(
      const customService = new EmbeddingService({
        apiKey: 'custom-key',
        model: 'text-embedding-3-small',
        cacheEnabled: false
      });

      expect(customService).toBeDefined();
    });

    it('should handle cache disabled', async () => {
      embeddingService = new EmbeddingService(
      const noCacheService = new EmbeddingService({ cacheEnabled: false });

      // Mock OpenAI for this service
      const { OpenAI } = await import('openai');
      const mockOpenAINoCache = OpenAI();
      mockOpenAINoCache.embeddings.create.mockResolvedValue({
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 5 }
      });

      // Both calls should hit the API
      await noCacheService.generateEmbedding('test');
      await noCacheService.generateEmbedding('test');

      expect(mockOpenAINoCache.embeddings.create).toHaveBeenCalledTimes(2);
    });
  });

  describe('Error Handling', () => {
    it('should handle network timeouts', async () => {
      mockOpenAI.embeddings.create.mockRejectedValue(new Error('Request timeout'));

      await expect(embeddingService.generateEmbedding('test')).rejects.toThrow('Request timeout');
    });

    it('should handle invalid responses', async () => {
      mockOpenAI.embeddings.create.mockResolvedValue({
        data: [], // Empty data - invalid
        usage: { total_tokens: 0 }
      });

      await expect(embeddingService.generateEmbedding('test')).rejects.toThrow();
    });

    it('should handle malformed input', async () => {
      await expect(embeddingService.generateEmbedding(null as any)).rejects.toThrow();
      await expect(embeddingService.generateEmbedding(undefined as any)).rejects.toThrow();
    });
  });

  describe('Edge Cases', () => {
    it('should handle very long text', async () => {
      const longText = 'a'.repeat(1000);
      mockOpenAI.embeddings.create.mockResolvedValue({
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 250 }
      });

      const result = await embeddingService.generateEmbedding(longText);

      expect(result.text).toBe(longText);
      expect(result.embedding).toEqual(sampleEmbedding);
    });

    it('should handle special characters', async () => {
      const unicodeText = 'Hello 世界 🌍 ñáéíóú';
      mockOpenAI.embeddings.create.mockResolvedValue({
        data: [{ embedding: sampleEmbedding }],
        usage: { total_tokens: 10 }
      });

      const result = await embeddingService.generateEmbedding(unicodeText);

      expect(result.text).toBe(unicodeText);
      expect(result.embedding).toEqual(sampleEmbedding);
    });
  });
});
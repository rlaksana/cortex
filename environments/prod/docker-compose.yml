# ============================================================================
# CORTEX MEMORY MCP - PRODUCTION ENVIRONMENT CONFIGURATION
# ============================================================================
# Production configuration with high availability and performance optimization
#
# Features:
# - High availability with redundancy
# - Performance optimization and scaling
# - Security hardening and monitoring
# - Comprehensive backup and disaster recovery
#
# Usage:
#   docker-compose -f environments/prod/docker-compose.yml up -d
#   docker-compose -f environments/prod/docker-compose.yml down
#
# IMPORTANT: This configuration assumes:
# - Production-grade hardware and networking
# - External load balancer for HA
# - Proper SSL certificates
# - Production secrets management

version: '3.8'

networks:
  cortex-prod-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16

  cortex-prod-monitoring:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.26.0.0/16

volumes:
  qdrant-prod-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/data/qdrant

  prometheus-prod-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/data/prometheus

  grafana-prod-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/data/grafana

  alertmanager-prod-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/data/alertmanager

  cortex-prod-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/logs

  cortex-prod-backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/backups

services:
  # Qdrant Vector Database - Primary Instance
  qdrant-primary:
    image: qdrant/qdrant:v1.7.4
    container_name: cortex-qdrant-primary
    restart: unless-stopped
    ports:
      - '26333:6333'  # HTTP API
      - '26334:6334'  # gRPC API
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=WARN  # Reduced logging for production
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=64
      - QDRANT__STORAGE__PERFORMANCE__SEARCH_RATE_LIMIT_DISABLED=false
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCHES_PER_REQUEST=200
      - QDRANT__SERVICE__TELEMETRY_DISABLED=true
    volumes:
      - qdrant-prod-data:/qdrant/storage
      - ../docker/qdrant/snapshots:/qdrant/snapshots
      - ../docker/qdrant/config/production:/qdrant/config:ro
    networks:
      - cortex-prod-network
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
      placement:
        constraints:
          - node.labels.database == true
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6333/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # Cortex Memory MCP - Primary Instance
  cortex-mcp-primary:
    build:
      context: ../..
      dockerfile: docker/Dockerfile
      target: runtime
    container_name: cortex-mcp-primary
    restart: unless-stopped
    ports:
      - "3000:3000"  # Health check endpoint
      - "9090:9090"  # Metrics endpoint
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=warn
      - QDRANT_HOST=qdrant-primary
      - QDRANT_PORT=6333
      - MCP_SERVER_NAME=cortex-mcp-primary
      - INSTANCE_ID=primary
      - ENABLE_METRICS=true
      - METRICS_PORT=9090
      - HEALTH_CHECK_PORT=3000
      - JWT_SECRET=${JWT_SECRET}
      - API_KEY=${API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SESSION_SECRET=${SESSION_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - RATE_LIMIT_WINDOW_MS=60000
      - RATE_LIMIT_MAX_REQUESTS=1000
      - MEMORY_MAX_ITEMS=100000
      - EMBEDDING_MODEL=text-embedding-3-large
      - BACKUP_SCHEDULE=0 2 * * *
      - BACKUP_RETENTION_DAYS=30
      - ENABLE_PERFORMANCE_MONITORING=true
      - ENABLE_SECURITY_MONITORING=true
      - ENABLE_AUDIT_LOGGING=true
      - CLUSTER_MODE=primary
      - REDIS_HOST=redis-cluster
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - cortex-prod-logs:/app/logs
      - cortex-prod-backups:/app/backups
      - ../docker/cortex/config/production:/app/config:ro
    networks:
      - cortex-prod-network
      - cortex-prod-monitoring
    depends_on:
      qdrant-primary:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 12G
        reservations:
          cpus: '2.0'
          memory: 6G
      placement:
        constraints:
          - node.labels.application == true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # Cortex Memory MCP - Secondary Instance (HA)
  cortex-mcp-secondary:
    build:
      context: ../..
      dockerfile: docker/Dockerfile
      target: runtime
    container_name: cortex-mcp-secondary
    restart: unless-stopped
    ports:
      - "3001:3000"  # Health check endpoint
      - "9091:9090"  # Metrics endpoint
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=warn
      - QDRANT_HOST=qdrant-primary
      - QDRANT_PORT=6333
      - MCP_SERVER_NAME=cortex-mcp-secondary
      - INSTANCE_ID=secondary
      - ENABLE_METRICS=true
      - METRICS_PORT=9090
      - HEALTH_CHECK_PORT=3000
      - JWT_SECRET=${JWT_SECRET}
      - API_KEY=${API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SESSION_SECRET=${SESSION_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - RATE_LIMIT_WINDOW_MS=60000
      - RATE_LIMIT_MAX_REQUESTS=1000
      - MEMORY_MAX_ITEMS=100000
      - EMBEDDING_MODEL=text-embedding-3-large
      - BACKUP_SCHEDULE=0 3 * * *
      - BACKUP_RETENTION_DAYS=30
      - ENABLE_PERFORMANCE_MONITORING=true
      - ENABLE_SECURITY_MONITORING=true
      - ENABLE_AUDIT_LOGGING=true
      - CLUSTER_MODE=secondary
      - PRIMARY_HOST=cortex-mcp-primary
      - REDIS_HOST=redis-cluster
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
    volumes:
      - cortex-prod-logs:/app/logs
      - ../docker/cortex/config/production:/app/config:ro
    networks:
      - cortex-prod-network
      - cortex-prod-monitoring
    depends_on:
      qdrant-primary:
        condition: service_healthy
      cortex-mcp-primary:
        condition: service_healthy
      redis-cluster:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 12G
        reservations:
          cpus: '2.0'
          memory: 6G
      placement:
        constraints:
          - node.labels.application == true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "10"

  # Redis Cluster for Session Management
  redis-cluster:
    image: redis:7-alpine
    container_name: cortex-redis-cluster
    restart: unless-stopped
    ports:
      - "26379:6379"
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
    volumes:
      - cortex-prod-redis-data:/data
      - ../docker/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - cortex-prod-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1.5G
      placement:
        constraints:
          - node.labels.cache == true
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Production Load Balancer (Nginx)
  nginx-lb:
    image: nginx:1.25-alpine
    container_name: cortex-nginx-lb
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ../docker/nginx/nginx-prod.conf:/etc/nginx/nginx.conf:ro
      - ../docker/nginx/conf.d:/etc/nginx/conf.d:ro
      - ../docker/nginx/ssl:/etc/nginx/ssl:ro
      - nginx-prod-logs:/var/log/nginx
      - ../docker/nginx/lua:/etc/nginx/lua:ro
    networks:
      - cortex-prod-network
    depends_on:
      - cortex-mcp-primary
      - cortex-mcp-secondary
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      placement:
        constraints:
          - node.labels.loadbalancer == true
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Prometheus - Production
  prometheus:
    image: prom/prometheus:v2.47.2
    container_name: cortex-prometheus-prod
    restart: unless-stopped
    ports:
      - "29090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=90d'
      - '--storage.tsdb.retention.size=200GB'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.external-url=https://metrics.cortex-mcp.example.com'
      - '--storage.remote.read-concurrent-limit=20'
      - '--storage.remote.read-sample-limit=5e7'
      - '--storage.remote.read-byte-limit=1e9'
    volumes:
      - ../docker/prometheus/production:/etc/prometheus:ro
      - prometheus-prod-data:/prometheus
    networks:
      - cortex-prod-monitoring
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
      placement:
        constraints:
          - node.labels.monitoring == true
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Grafana - Production
  grafana:
    image: grafana/grafana:10.2.0
    container_name: cortex-grafana-prod
    restart: unless-stopped
    ports:
      - "23000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_COOKIE_SAMESITE=strict
      - GF_SECURITY_CONTENT_TYPE_PROTECTION=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY=true
      - GF_SERVER_DOMAIN=grafana.cortex-mcp.example.com
      - GF_SERVER_ROOT_URL=https://grafana.cortex-mcp.example.com/
      - GF_SMTP_ENABLED=true
      - GF_SMTP_HOST=${SMTP_HOST}
      - GF_SMTP_USER=${SMTP_USER}
      - GF_SMTP_PASSWORD=${SMTP_PASSWORD}
      - GF_SMTP_FROM_ADDRESS=${SMTP_FROM}
      - GF_DATABASE_SSL_MODE=require
      - GF_AUTH_LDAP_ENABLED=true
    volumes:
      - grafana-prod-data:/var/lib/grafana
      - ../docker/grafana/provisioning/production:/etc/grafana/provisioning:ro
      - ../docker/grafana/dashboards/production:/var/lib/grafana/dashboards:ro
    networks:
      - cortex-prod-monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
      placement:
        constraints:
          - node.labels.monitoring == true
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Alertmanager - Production
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: cortex-alertmanager-prod
    restart: unless-stopped
    ports:
      - "29093:9093"
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=https://alerts.cortex-mcp.example.com'
      - '--cluster.listen-address=0.0.0.0:9094'
      - '--cluster.peer=alertmanager-secondary:9094'
    volumes:
      - ../docker/alertmanager/production:/etc/alertmanager:ro
      - alertmanager-prod-data:/alertmanager
    networks:
      - cortex-prod-monitoring
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      placement:
        constraints:
          - node.labels.monitoring == true
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Backup Service - Production
  backup-service:
    build:
      context: ../..
      dockerfile: docker/Dockerfile.backup
    container_name: cortex-backup-prod
    restart: unless-stopped
    environment:
      - BACKUP_SCHEDULE=${BACKUP_SCHEDULE:-0 2 * * *}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
      - QDRANT_HOST=qdrant-primary
      - QDRANT_PORT=6333
      - S3_BUCKET=${S3_BACKUP_BUCKET}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - BACKUP_ENCRYPTION_KEY=${BACKUP_ENCRYPTION_KEY}
      - ENABLE_CLOUD_BACKUP=true
      - ENABLE_LOCAL_BACKUP=true
    volumes:
      - cortex-prod-backups:/app/backups
      - ../docker/backup/config/production:/app/config:ro
    networks:
      - cortex-prod-network
    depends_on:
      qdrant-primary:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  # Log Aggregation (Fluentd)
  fluentd:
    image: fluent/fluentd:v1.16-debian-1
    container_name: cortex-fluentd-prod
    restart: unless-stopped
    ports:
      - "24224:24224"
    environment:
      - FLUENTD_CONF=fluent.conf
    volumes:
      - cortex-prod-logs:/var/log/fluentd
      - ../docker/fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - ../docker/fluentd/plugins:/fluentd/plugins
    networks:
      - cortex-prod-network
      - cortex-prod-monitoring
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "3"

volumes:
  nginx-prod-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/logs/nginx

  cortex-prod-redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/cortex-prod/data/redis